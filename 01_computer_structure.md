# 제1장. 컴퓨터 구조 (Computer Structure)

> **[심화] (Deep Dive)** 섹션이 추가되었습니다.

## 📌 왜 배워야 하나요? (Why?)
데이터 엔지니어와 ML 전문가에게 '컴퓨터 구조'는 단순한 하드웨어 지식이 아닙니다. **대용량 데이터 분산 처리(Spark, Hadoop)**나 **모델 학습(GPU 가속)** 시 발생하는 병목 현상(Bottleneck)의 원인을 이해하려면 CPU, 메모리, 캐시, I/O의 작동 원리를 알아야 합니다.

---

## 1. 컴퓨터 구조의 큰 그림 (Big Picture)

### 🔑 핵심 개념
*   **컴퓨터 구조 (Computer Architecture)**: 하드웨어와 소프트웨어 사이의 인터페이스를 정의합니다. 크게 **ISA(명령어 집합 구조)**와 **마이크로아키텍처(구현)**로 나뉩니다.
*   **ISA (Instruction Set Architecture)**: CPU가 이해하는 명령어 집합(S/W)과 하드웨어(H/W) 사이의 약속입니다. (예: x86, ARM)
*   **마이크로아키텍처 (Microarchitecture)**: ISA를 물리적으로 구현한 방식입니다. 같은 x86 ISA라도 인텔과 AMD의 내부 설계는 다를 수 있습니다.

### 🏗️ 폰 노이만 vs 하버드 구조
*   **폰 노이만 구조 (Von Neumann Architecture)**:
    *   **특징**: 명령어(코드)와 데이터가 **하나의 메모리**에 저장됩니다. 그리고 하나의 버스(Bus)를 공유합니다.
    *   **병목 현상 (Von Neumann Bottleneck)**: CPU 속도는 빠른데, 메모리 속도가 느리고 버스가 하나라 속도 차이가 발생합니다.
*   **하버드 구조 (Harvard Architecture)**:
    *   **특징**: 명령어 메모리와 데이터 메모리가 **물리적으로 분리**되어 있습니다. 동시에 접근 가능하여 속도가 빠릅니다. (주로 캐시 메모리나 임베디드 시스템에서 사용)

---

## 2. CPU (Central Processing Unit)

CPU는 컴퓨터의 두뇌로, **ALU(연산)**, **CU(제어)**, **레지스터(기억)**로 구성됩니다.

### ⚙️ 구성 요소
1.  **ALU (Arithmetic Logic Unit)**: 덧셈, 뺄셈 같은 **산술 연산**과 AND, OR 같은 **논리 연산**을 수행합니다.
2.  **CU (Control Unit)**: 명령어를 해석하고 각 장치에 제어 신호(Control Signal)를 보냅니다.
3.  **레지스터 (Register)**: CPU 내부의 가장 빠르고 작은 임시 저장 공간입니다.

### 📝 주요 레지스터 (Must Know)
*   **PC (Program Counter)**: **다음에 실행할 명령어의 주소**를 저장합니다.
*   **IR (Instruction Register)**: **현재 실행 중인 명령어**를 저장합니다.
*   **MAR (Memory Address Register)**: 읽거나 쓸 메모리의 **주소**를 저장합니다.
*   **MBR (Memory Buffer Register)**: 메모리에서 읽어온 **데이터**나 쓸 데이터를 잠시 저장합니다. (MDR이라고도 함)
*   **플래그 레지스터 (Flag Register)**: 연산 결과(음수, 0, 오버플로우 등)나 CPU 상태를 저장합니다.
*   **스택 포인터 (Stack Pointer)**: 스택의 최상단(Top) 주소를 가리킵니다.

---

## 3. 명령어 사이클 (Instruction Cycle)

CPU가 하나의 명령어를 처리하는 과정입니다.

```mermaid
graph LR
    A[인출 (Fetch)] --> B[해석 (Decode)]
    B --> C[실행 (Execute)]
    C --> D[저장 (Store)]
    D --> E{인터럽트 발생?}
    E -- Yes --> F[인터럽트 처리]
    E -- No --> A
    F --> A
```

1.  **인출 사이클 (Fetch Cycle)**: PC가 가리키는 주소에서 명령어를 가져와 IR에 저장합니다.
2.  **실행 사이클 (Execute Cycle)**: 가져온 명령어를 ALU가 실행합니다.
3.  **간접 사이클 (Indirect Cycle)**: 명령어의 주소가 간접 주소(포인터 등)일 때, 유효 주소를 얻기 위해 한 번 더 메모리에 접근합니다.
4.  **인터럽트 사이클 (Interrupt Cycle)**: 예외 상황(I/O 요청, 오류 등)이 발생하면 현재 작업을 멈추고 처리 루틴으로 이동합니다.

---

## 4. 성능 향상 기법

단순히 클럭(Clock)만 높이는 것은 한계가 있습니다. 병렬 처리를 통해 성능을 높입니다.

*   **파이프라이닝 (Pipelining)**: 명령어 처리 과정을 단계별(Fetch, Decode, Execute...)로 나누어, 동시에 여러 명령어를 겹쳐서 실행하는 기법입니다. "공장 조립 라인"과 같습니다.
*   **슈퍼스칼라 (Superscalar)**: CPU 내에 여러 개의 파이프라인을 두어, 한 클럭에 여러 명령어를 동시에 인출하고 실행합니다.
*   **CISC vs RISC**:
    *   **CISC (Complex ISA)**: 명령어 개수가 많고 복잡함. 가변 길이. (Intel x86) -> 하드웨어가 복잡하지만 코드 길이는 짧음.
    *   **RISC (Reduced ISA)**: 명령어 개수가 적고 단순함. 고정 길이. (ARM) -> 파이프라이닝 최적화에 유리.

---

## 5. 메모리 계층 구조 (Memory Hierarchy)

"빠를수록 비싸고 용량이 적다"라는 법칙에 따라 계층을 구성합니다.

### 🔺 계층 구조
1.  **레지스터 (Registers)**: CPU 내부, 가장 빠름.
2.  **캐시 (Cache)**: L1, L2, L3 캐시. SRAM 사용.
3.  **메모리 (RAM)**: 주기억장치. DRAM 사용.
4.  **보조기억장치 (Storage)**: HDD, SSD. 비휘발성.

### 📍 지역성 (Locality of Reference)
캐시가 효율적으로 동작하는 원리입니다.
*   **시간 지역성 (Temporal Locality)**: 한 번 사용된 데이터는 곧 다시 사용될 가능성이 높다. (예: 반복문의 변수)
*   **공간 지역성 (Spatial Locality)**: 사용된 데이터의 주변 데이터가 사용될 가능성이 높다. (예: 배열 순회)

---

## 6. 보조기억장치와 입출력 (I/O)

*   **RAID (Redundant Array of Independent Disks)**: 여러 개의 디스크를 묶어 성능(속도)이나 신뢰성(백업)을 높이는 기술. (RAID 0, 1, 5, 10 등)
*   **DMA (Direct Memory Access)**: **면접 단골 질문!**
    *   CPU를 거치지 않고, **입출력 장치와 메모리가 직접 데이터를 주고받는 방식**입니다.
    *   CPU 부하를 줄여 시스템 전체 성능을 높입니다.

---

## 🎓 Data Engineer & ML Interview Q&A

**Q1. 프로세스가 실행될 때 코드와 데이터는 메모리의 어디에 저장되나요? (폰 노이만 구조 관련)**
> **A.** 폰 노이만 구조 컴퓨터에서는 실행 파일(프로그램)이 보조기억장치에서 **RAM(주기억장치)**으로 로드되어야 실행됩니다. 이때 코드는 **Code(Text) 영역**에, 전역 변수는 **Data 영역**에, 함수 호출 정보는 **Stack 영역**에, 동적 할당된 메모리는 **Heap 영역**에 저장됩니다. CPU는 폰 노이만 구조에 따라 이 메모리에서 명령어와 데이터를 가져와 처리합니다.

**Q2. 캐시 히트(Cache Hit)와 미스(Miss)가 시스템 성능에 미치는 영향은? 특히 대용량 데이터 처리 시에는?**
> **A.** 캐시 히트는 CPU가 필요한 데이터를 빠른 캐시 메모리에서 바로 찾는 경우를 말하며, 이는 성능의 핵심입니다. 반면 캐시 미스가 발생하면 느린 메인 메모리까지 접근해야 하므로 병목이 발생합니다.
> **DE 관점**: 대용량 데이터를 처리(예: 행렬 곱셈)할 때 **공간 지역성**을 고려하여 데이터를 연속적으로 배치하거나(Row-major vs Column-major), 블록 단위로 처리하는 등의 최적화를 통해 캐시 히트율을 높여야 처리 속도를 획기적으로 개선할 수 있습니다.

**Q3. DMA(Direct Memory Access)가 없다면 어떤 문제가 발생하나요?**
> **A.** DMA가 없다면 디스크 I/O나 네트워크 패킷 수신 같은 입출력 작업 시마다 CPU가 직접 데이터를 옮겨야 합니다(PIO 모드). 이렇게 되면 CPU는 연산에 집중하지 못하고 단순 데이터 이동에 시간을 뺏기게 되어 전체 시스템 효율이 급격히 저하됩니다. DMA를 사용함으로써 CPU는 I/O 명령만 내리고 다른 작업을 수행할 수 있습니다.

---

## 🔬 Deep Dive: 고성능 아키텍처의 비밀

여기서는 단순한 개념을 넘어, 실제 CPU 성능 최적화의 기술적 난제들을 다룹니다.

### 1. 파이프라인 해저드 (Pipeline Hazards)
파이프라인이 매끄럽게 흐르지 못하고 멈추는(Stall) 현상입니다.

*   **구조적 해저드 (Structural Hazard)**: 하드웨어 자원 부족(예: 메모리 하나에 동시에 접근). -> 하버드 구조(명령어/데이터 캐시 분리)로 해결.
*   **데이터 해저드 (Data Hazard)**: 이전 명령어의 연산 결과가 아직 나오지 않았는데 다음 명령어가 그 데이터를 필요로 할 때.
    *   **해결책**:
        1.  **Stall**: 그냥 기다림 (성능 저하).
        2.  **Forwarding (Bypassing)**: ALU 연산 결과를 레지스터에 쓰기 전에 다음 명령어로 바로 전달.
*   **제어 해저드 (Control Hazard)**: `if`문이나 분기(Branch) 명령어로 인해 다음에 실행할 명령어를 미리 알 수 없을 때.
    *   **해결책**: **분기 예측 (Branch Prediction)**. (틀리면 파이프라인 비우고 다시 실행 -> Flush 비용 발생).

### 2. 캐시 메모리 동작 원리 (Cache Mapping)
메인 메모리의 큰 주소를 작은 캐시 주소로 어떻게 매핑할까요?

*   **Direct Mapping**: 메모리 주소를 나눗셈(Modulo)하여 캐시의 특정 한 위치에만 저장. (구현 간단, 충돌 잦음)
*   **Fully Associative**: 비어있는 아무 곳에나 저장. (충돌 없으나 검색 속도 느림 - 하드웨어 복잡)
*   **Set Associative**: 둘의 절충안. 특정 세트(Set)를 먼저 찾고, 그 안의 라인(Way) 중 하나에 저장. (현대 CPU가 사용하는 방식, 예: 8-way Set Associative)

### 3. 가상 메모리 하드웨어: TLB
가상 주소(VA)를 물리 주소(PA)로 변환하는 과정은 매번 페이지 테이블(메모리)을 읽어야 하므로 **너무 느립니다**.
*   **TLB (Translation Lookaside Buffer)**: 주소 변환 전용 **하드웨어 캐시**.
*   CPU는 먼저 TLB를 확인하고(TLB Hit), 없으면 페이지 테이블을 봅니다(TLB Miss).
*   **Context Switch 시 TLB Flush**: 프로세스가 바뀌면 가상 주소 체계가 바뀌므로 TLB를 비워야 합니다. 이것이 문맥 교환 비용의 큰 원인 중 하나입니다. (이를 줄이기 위해 PCID/ASID 같은 식별자를 쓰기도 합니다)