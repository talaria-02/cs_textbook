# 제2장. 운영체제 (Operating System)

> **[심화] (Deep Dive)** 섹션이 추가되었습니다.

## 📌 왜 배워야 하나요? (Why?)
운영체제는 하드웨어 자원(CPU, Memory)을 효율적으로 관리하는 '매니저'입니다. 서버 개발자나 데이터 엔지니어가 **동시 접속 처리(Concurrency)**, **메모리 누수(Memory Leak)**, **데드락(Deadlock)** 문제를 해결하려면 OS가 자원을 어떻게 스케줄링하고 관리하는지 이해해야 합니다.

---

## 1. 운영체제의 큰 그림

### 🔑 핵심 개념
*   **운영체제 (OS)**: 사용자에게 편리한 인터페이스(UI)를 제공하고, 시스템 자원을 효율적으로 관리하는 시스템 소프트웨어입니다.
*   **커널 (Kernel)**: OS의 핵심 부품입니다. 하드웨어를 직접 제어하고, 프로세스 관리, 메모리 관리 등 중요한 기능을 수행합니다.

### 🛡️ 이중 모드 (Dual Mode)
시스템을 보호하기 위해 CPU 실행 모드를 두 가지로 나눕니다.
1.  **사용자 모드 (User Mode)**: 일반 애플리케이션이 실행되는 모드. 중요한 하드웨어 자원에 직접 접근할 수 없습니다.
2.  **커널 모드 (Kernel Mode)**: OS 커널이 실행되는 모드. 모든 시스템 자원에 접근 권한을 가집니다.
3.  **시스템 호출 (System Call)**: 사용자 모드의 프로그램이 파일 읽기, 쓰기 등 커널 기능이 필요할 때 **커널에 요청하는 인터페이스**입니다. (예: `open()`, `fork()`, `read()`)

---

## 2. 프로세스와 스레드 (Process & Thread)

가장 빈번하게 등장하는 면접 주제입니다.

### 🔄 프로세스 vs 스레드
*   **프로세스 (Process)**: **실행 중인 프로그램**. 메모리에 적재되어 CPU 할당을 받습니다. 자신만의 독립적인 메모리 공간(Code, Data, Stack, Heap)을 가집니다.
*   **스레드 (Thread)**: **프로세스 내의 실행 흐름의 단위**. 프로세스의 메모리(Code, Data, Heap)를 공유하고, 자신만의 **Stack**과 **PC(Program Counter)**만 가집니다.

### 📊 주요 키워드
*   **PCB (Process Control Block)**: OS가 프로세스를 제어하기 위해 정보를 저장하는 자료구조 (PID, 상태, 레지스터 값 등).
*   **문맥 교환 (Context Switch)**: CPU가 실행 중인 프로세스를 바꾸기 위해, 이전 프로세스 상태(Context)를 PCB에 저장하고 다음 프로세스 정보를 로드하는 작업입니다. **오버헤드(비용)**가 발생합니다.
*   **멀티 프로세스 (Multi-Process)**: 하나의 프로그램을 여러 프로세스로 구성. 안정성이 높으나(하나 죽어도 영향 X), 문맥 교환 비용이 크고 통신(IPC)이 복잡합니다.
*   **멀티 스레드 (Multi-Thread)**: 하나의 프로세스에 여러 스레드 생성. 자원 공유로 효율적이고 빠르지만, **동기화 문제**가 발생할 수 있습니다.

---

## 3. CPU 스케줄링 (Scheduling)

준비 큐(Ready Queue)에 있는 프로세스 중 누구에게 CPU를 줄지 결정하는 정책입니다.

### ⏱️ 스케줄링 알고리즘
*   **선점형 (Preemptive)**: OS가 강제로 CPU를 빼앗을 수 있음. (현대 OS 대부분)
    *   **라운드 로빈 (RR)**: 정해진 시간(Time Slice)만큼만 쓰고 다음 프로세스에게 넘김. 응답 시간이 빠름.
    *   **SRT (Shortest Remaining Time)**: 남은 시간이 가장 짧은 것부터 수행.
    *   **다단계 피드백 큐 (MLFQ)**: 여러 단계의 큐를 두고, CPU를 많이 쓰는 프로세스의 우선순위를 낮추는 방식.
*   **비선점형 (Non-Preemptive)**: 프로세스가 종료되거나 대기할 때까지 빼앗지 않음.
    *   **FCFS (First-Come First-Served)**: 먼저 온 순서대로. (소위 '선착순')
    *   **SJF (Shortest Job First)**: 실행 시간이 가장 짧은 것부터. 평균 대기 시간을 최소화하지만, 긴 프로세스는 기아(Starvation) 현상 발생.

---

## 4. 프로세스 동기화 (Synchronization)

여러 스레드가 공유 자원에 동시에 접근하면 데이터가 꼬이는 **경쟁 상태(Race Condition)**가 발생합니다. 이를 막는 것이 동기화입니다.

### 🔒 해결 기법
*   **임계 구역 (Critical Section)**: 공유 자원에 접근하는 코드 영역. 한 번에 하나의 스레드만 들어가야 함.
*   **뮤텍스 (Mutex)**: 화장실 키(Key)와 같음. 락(Lock)을 획득한 스레드만 진입 가능. (Locking Mechanism)
*   **세마포어 (Semaphore)**: 신호등(Signaling) 개념입니다.
    *   **Counting Semaphore**: 빈 칸의 개수(Count)를 관리하여 여러 스레드가 동시에 접근 가능합니다.
    *   **Binary Semaphore**: 0과 1 두 가지 값만 가져 Mutex와 유사하게 동작합니다.
*   **모니터 (Monitor)**: 프로그래밍 언어 차원에서 동기화를 쉽게 사용하도록 제공하는 고수준 도구 (예: Java `synchronized`).

---

## 5. 교착 상태 (Deadlock)

두 개 이상의 프로세스가 서로 상대방의 자원을 기다리며 무한 대기에 빠지는 상황입니다.

### ⚠️ 발생 4대 조건 (모두 만족해야 발생)
1.  **상호 배제 (Mutual Exclusion)**: 한 번에 하나만 사용 가능.
2.  **점유와 대기 (Hold and Wait)**: 자원을 가진 채로 다른 자원을 기다림.
3.  **비선점 (No Preemption)**: 뺏어올 수 없음.
4.  **환형 대기 (Circular Wait)**: 꼬리에 꼬리를 물고 기다림.

---

## 6. 가상 메모리 (Virtual Memory)

물리 메모리(RAM) 크기의 한계를 극복하기 위해, 보조기억장치 일부를 메모리처럼 사용하는 기술입니다.

### 📄 페이징 (Paging)
*   프로세스를 일정한 크기의 **페이지(Page)**로 자르고, 물리 메모리를 **프레임(Frame)**으로 잘라 매핑합니다.
*   **외부 단편화** 해결, 그러나 **페이지 부재(Page Fault)** 발생 가능.
*   **페이지 교체 알고리즘**: 메모리가 꽉 찼을 때 누굴 내쫓을까?
    *   **FIFO**: 먼저 들어온 놈.
    *   **LRU (Least Recently Used)**: **가장 오랫동안 사용되지 않은 놈**. (가장 널리 쓰임)
    *   **LFU (Least Frequently Used)**: 사용 횟수가 가장 적은 놈.

---

## 🎓 Data Engineer & ML Interview Q&A

**Q1. 프로세스와 스레드의 결정적인 차이는 무엇인가요? 멀티 프로세스 대신 멀티 스레드를 쓰는 이유는?**
> **A.** 프로세스는 독립적인 메모리 공간을 갖지만, 스레드는 Stack을 제외한 메모리 영역을 공유한다는 점이 다릅니다.
> 멀티 스레드를 사용하는 이유는 자원을 공유하므로 **생성 및 컨텍스트 스위칭 비용이 적고**, 스레드 간 데이터 통신이 메모리를 통해 바로 이루어져 빠르기 때문입니다. 다만, 동기화 문제에 주의해야 합니다.

**Q2. 데드락(Deadlock)을 해결하는 방법은 무엇인가요?**
> **A.** 데드락의 4가지 조건(상호 배제, 점유 대기, 비선점, 환형 대기) 중 **하나라도 깨뜨리면** 해결됩니다.
> 가장 현실적인 방법은 **회피(Avoidance)** 기법으로, 자원을 할당할 때 데드락 가능성을 검사하는 **은행원 알고리즘(Banker's Algorithm)**이 대표적입니다. 또는 데드락 발생 시 프로세스를 강제 종료하는 **탐지 및 회복** 기법을 사용하기도 합니다.

**Q3. 페이징(Paging) 기법에서 LRU 알고리즘이 왜 중요한가요?**
> **A.** 실제 프로그램은 참조 지역성(Locality)을 가지므로, 최근에 사용된 데이터가 다시 사용될 확률이 높습니다. LRU는 이 원리를 이용하여 페이지 부재(Page Fault)를 효과적으로 줄여 시스템 성능을 유지합니다. 운영체제뿐만 아니라 **데이터베이스 버퍼 캐시**나 **웹 캐시** 전략에서도 핵심적으로 사용됩니다.

---

## 🔬 Deep Dive: 운영체제의 내부로 (Kernel Internals)

### 1. 리눅스 스케줄러: CFS (Completely Fair Scheduler)
단순한 라운드 로빈이나 우선순위 큐가 아닙니다. 리눅스는 **Red-Black Tree**를 사용합니다.
*   **vruntime (Virtual Runtime)**: 각 프로세스가 CPU를 사용한 시간을 가중치를 고려해 정규화한 값.
*   **작동 원리**: `vruntime`이 가장 작은 프로세스를 RB-Tree의 왼쪽 끝에서 O(1)에 가깝게 찾아네어(캐싱됨) CPU를 할당합니다.
*   **공정성**: 우선순위가 높은 프로세스는 `vruntime`이 천천히 증가하여 더 오래 CPU를 점유하게 됩니다.

### 2. 동기화 객체의 내부 구현 (Synchronization)
뮤텍스와 세마포어는 어떻게 구현될까요? 단순히 `int lock = 0;`으로 하면 안 됩니다.
*   **TAS (Test-And-Set) / CAS (Compare-And-Swap)**: 하드웨어 수준에서 지원하는 **원자적(Atomic) 명령어**입니다. "값을 확인하고 수정하는 것"을 한 번에 수행하여 중간에 다른 스레드가 끼어들지 못하게 합니다.
*   **Spinlock**: 루프를 돌면서(Busy Waiting) 락이 풀릴 때까지 계속 감시합니다. 문맥 교환 비용이 없지만 CPU를 낭비합니다. (짧은 시간 대기에 적합)
*   **Mutex/Semaphore**: 락을 얻지 못하면 프로세스를 **Sleep(Blocking)** 상태로 만들고 대기 큐에 넣습니다. CPU 낭비는 없지만 문맥 교환 비용이 듭니다. (긴 시간 대기에 적합)
    *   **차이점**: Mutex는 **Locking(소유권)** 개념이라 락을 건 스레드만 풀 수 있지만, Semaphore는 **Signaling(신호)** 개념이라 다른 스레드가 `signal()`을 보내 빈자리를 릴리즈할 수 있습니다.

### 3. 메모리 관리 심화
*   **Thrashing (스레싱)**: 페이지 부재가 너무 빈번하게 발생하여 프로세스 수행 시간보다 페이지 교체에 쓰는 시간이 더 많아지는 현상. (시스템 멈춤)
*   **Working Set Model**: 프로세스가 일정 시간 동안 자주 참조하는 페이지들의 집합을 메모리에 상주시켜 스레싱을 방지합니다.
*   **Copy-on-Write (COW)**: `fork()`로 자식 프로세스를 생성할 때, 부모의 메모리를 바로 복사하지 않고 **공유**하다가, 누군가 "쓰기(Write)" 작업을 할 때 비로소 복사합니다. (프로세스 생성 속도 획기적 단축)

### 4. IPC (Inter-Process Communication) 성능 비교
*   **Pipe / Socket**: 데이터 복사(User <-> Kernel)가 발생하여 오버헤드가 있음.
*   **Shared Memory**: 물리 메모리 일부를 공유하므로 **가장 빠름**. 하지만 **동기화 문제**를 직접 해결해야 함.
*   **Message Queue**: 커널이 관리하는 메시지 리스트. 비동기식 처리에 유리.